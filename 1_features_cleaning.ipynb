{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Setup and Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Navigate to the project folder\n",
        "%cd #YOUR PATH TO THE NOTEBOOK IN GOOGLE COLAB\n",
        "\n",
        "# Import dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "g2BH_-3DlMrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from configuration import experiment_id as EXPERIMENT_ID\n",
        "from configuration import data_root as DATA_ROOT\n",
        "from configuration import data_path as DATA_PATH\n",
        "\n",
        "DATA_PATH"
      ],
      "metadata": {
        "id": "1suBu4ws9v-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ELA cleaning"
      ],
      "metadata": {
        "id": "AtHKuA1YrMth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ELA feature cleaning\n",
        "def clean_ela_features(data_root, columns):\n",
        "  \"\"\"Preprocess ELA features and return a cleaned DataFrame.\"\"\"\n",
        "  # Read data\n",
        "  filepath = f\"{data_root}/ela_feats-05D-n050.csv\"\n",
        "  df = pd.read_csv(filepath)\n",
        "  print(df)\n",
        "  print(df.shape)\n",
        "  # Select ELA features\n",
        "  df = df[[\"fid\", \"iid\"] + columns]\n",
        "  print(f\"Number of feature calculation runs per problem instance: {df.groupby(['fid', 'iid']).size().unique()}\")\n",
        "  # Calculate the final ELA feature value over multiple runs using MEAN aggregation\n",
        "  df = df.groupby([\"fid\", \"iid\"], as_index=False).mean()\n",
        "  # Rename id columns\n",
        "  df = df.rename(columns={\"fid\": \"f_id\", \"iid\": \"i_id\"})\n",
        "  return df"
      ],
      "metadata": {
        "id": "_gVS0StguuiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of ELA features, the others contain nans or are not relevent such as the cost of calculating a feature etc.\n",
        "columns = [\n",
        " 'cm_angle.dist_ctr2best.mean',\n",
        " 'cm_angle.dist_ctr2worst.mean',\n",
        " 'cm_angle.angle.mean',\n",
        "#  'cm_angle.costs_runtime',\n",
        " 'cm_grad.mean',\n",
        "#  'cm_grad.costs_runtime',\n",
        " 'disp.ratio_mean_02',\n",
        " 'disp.ratio_mean_05',\n",
        " 'disp.ratio_mean_10',\n",
        " 'disp.ratio_mean_25',\n",
        " 'disp.ratio_median_02',\n",
        " 'disp.ratio_median_05',\n",
        " 'disp.ratio_median_10',\n",
        " 'disp.ratio_median_25',\n",
        " 'disp.diff_mean_02',\n",
        " 'disp.diff_mean_05',\n",
        " 'disp.diff_mean_10',\n",
        " 'disp.diff_mean_25',\n",
        " 'disp.diff_median_02',\n",
        " 'disp.diff_median_05',\n",
        " 'disp.diff_median_10',\n",
        " 'disp.diff_median_25',\n",
        "#  'disp.costs_runtime',\n",
        " 'ela_conv.conv_prob',\n",
        " 'ela_conv.lin_prob',\n",
        " 'ela_conv.lin_dev.orig',\n",
        " 'ela_conv.lin_dev.abs',\n",
        "#  'ela_conv.costs_runtime',\n",
        " 'ela_curv.grad_norm.min',\n",
        " 'ela_curv.grad_norm.lq',\n",
        " 'ela_curv.grad_norm.mean',\n",
        " 'ela_curv.grad_norm.med',\n",
        " 'ela_curv.grad_norm.uq',\n",
        " 'ela_curv.grad_norm.max',\n",
        " 'ela_curv.grad_norm.sd',\n",
        " 'ela_curv.grad_scale.nas',\n",
        " 'ela_curv.hessian_cond.nas',\n",
        "#  'ela_curv.costs_fun_evals',\n",
        "#  'ela_curv.costs_runtime',\n",
        " 'ela_distr.skewness',\n",
        " 'ela_distr.kurtosis',\n",
        " 'ela_distr.number_of_peaks',\n",
        "#  'ela_distr.costs_runtime',\n",
        " 'ela_level.mmce_lda_10',\n",
        " 'ela_level.mmce_qda_10',\n",
        " 'ela_level.mmce_mda_10',\n",
        " 'ela_level.lda_qda_10',\n",
        " 'ela_level.lda_mda_10',\n",
        " 'ela_level.qda_mda_10',\n",
        " 'ela_level.mmce_lda_25',\n",
        " 'ela_level.mmce_qda_25',\n",
        " 'ela_level.mmce_mda_25',\n",
        " 'ela_level.lda_qda_25',\n",
        " 'ela_level.lda_mda_25',\n",
        " 'ela_level.qda_mda_25',\n",
        " 'ela_level.mmce_lda_50',\n",
        " 'ela_level.mmce_qda_50',\n",
        " 'ela_level.mmce_mda_50',\n",
        " 'ela_level.lda_qda_50',\n",
        " 'ela_level.lda_mda_50',\n",
        " 'ela_level.qda_mda_50',\n",
        "#  'ela_level.costs_runtime',\n",
        " 'ela_local.n_loc_opt.abs',\n",
        " 'ela_local.n_loc_opt.rel',\n",
        " 'ela_local.best2mean_contr.orig',\n",
        " 'ela_local.basin_sizes.avg_best',\n",
        " 'ela_local.basin_sizes.avg_non_best',\n",
        " 'ela_local.basin_sizes.avg_worst',\n",
        "#  'ela_local.fun_evals.min',\n",
        "#  'ela_local.fun_evals.lq',\n",
        "#  'ela_local.fun_evals.mean',\n",
        "#  'ela_local.fun_evals.median',\n",
        "#  'ela_local.fun_evals.uq',\n",
        "#  'ela_local.fun_evals.max',\n",
        "#  'ela_local.fun_evals.sd',\n",
        "#  'ela_local.costs_fun_evals',\n",
        "#  'ela_local.costs_runtime',\n",
        " 'ela_meta.lin_simple.adj_r2',\n",
        " 'ela_meta.lin_simple.intercept',\n",
        " 'ela_meta.lin_simple.coef.min',\n",
        " 'ela_meta.lin_simple.coef.max',\n",
        " 'ela_meta.lin_simple.coef.max_by_min',\n",
        " 'ela_meta.lin_w_interact.adj_r2',\n",
        " 'ela_meta.quad_simple.adj_r2',\n",
        " 'ela_meta.quad_simple.cond',\n",
        " 'ela_meta.quad_w_interact.adj_r2',\n",
        "#  'ela_meta.costs_runtime',\n",
        " 'ic.h.max',\n",
        " 'ic.eps.s',\n",
        " 'ic.eps.max',\n",
        " 'ic.eps.ratio',\n",
        " 'ic.m0',\n",
        "#  'ic.costs_runtime',\n",
        " 'nbc.nn_nb.sd_ratio',\n",
        " 'nbc.nn_nb.mean_ratio',\n",
        " 'nbc.nn_nb.cor',\n",
        " 'nbc.dist_ratio.coeff_var',\n",
        " 'nbc.nb_fitness.cor',\n",
        "#  'nbc.costs_runtime'\n",
        " ]\n",
        "len(columns)"
      ],
      "metadata": {
        "id": "LmW3agg4n9Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean ELA features\n",
        "df = clean_ela_features(DATA_ROOT, columns)\n",
        "\n",
        "# Save cleaned data\n",
        "df.to_csv(f\"{DATA_PATH}/X.csv\", index=False)"
      ],
      "metadata": {
        "id": "kbjP0pOjvaL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "m1qchS3NpaEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "def plot_feature_distribution(df, columns, title, data_path):\n",
        "  \"\"\"Plot and save the distribution of features.\"\"\"\n",
        "  plt.figure(figsize=(7, 20))\n",
        "  sns.boxplot(data=df[columns].melt(), x=\"value\", y=\"variable\", color='white')\n",
        "  # Save\n",
        "  plt.savefig(f\"{data_path}/{title}.png\", dpi=300)\n",
        "  plt.savefig(f\"{data_path}/{title}.pdf\", bbox_inches='tight')\n",
        "\n",
        "# Scale features\n",
        "def scale_features(df, columns):\n",
        "  \"\"\"Scale features using MinMaxScaler and return scaled DataFrame.\"\"\"\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  scaled_values = scaler.fit_transform(df[columns])\n",
        "  scaled_df = pd.DataFrame(scaled_values, columns=columns, index=df.index)\n",
        "  return scaled_df"
      ],
      "metadata": {
        "id": "XemInS-Owq6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect feature ranges\n",
        "df.describe().transpose()"
      ],
      "metadata": {
        "id": "L4zJqJfJAlnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot feature distribution\n",
        "plot_feature_distribution(df, columns, \"X_ELA_distribution_original\",  DATA_PATH)\n",
        "\n",
        "# Apply feature scaling\n",
        "scaled_df = scale_features(df, columns)\n",
        "plot_feature_distribution(scaled_df, columns, \"X_ELA_distribution_scaled\", DATA_PATH)"
      ],
      "metadata": {
        "id": "N5IuyzZsAhPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature correlation\n",
        "def heatmap(df: pd.DataFrame, figsize, font_scale, path, **kwargs):\n",
        "  \"\"\" Function to plot a heatmap.\"\"\"\n",
        "  # Set up figure\n",
        "  sns.set(style=\"white\", font_scale=font_scale)\n",
        "  plt.figure(figsize=figsize)\n",
        "  # Plot\n",
        "  ax = sns.heatmap(df, **kwargs)\n",
        "  cbar = ax.collections[0].colorbar\n",
        "  cbar.ax.tick_params(labelsize=25)\n",
        "  plt.tight_layout()\n",
        "  # save\n",
        "  plt.savefig(f\"{path}.png\", dpi=300)\n",
        "  plt.savefig(f\"{path}.pdf\")\n",
        "\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "K1SYEdQiomLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore feature correlation\n",
        "heatmap(df=df.set_index([\"f_id\", \"i_id\"]).corr(method=\"spearman\"), figsize=(25, 20), font_scale=1, path=f\"{DATA_PATH}/X_ELA_correlation_spearman\", vmin=-1, vmax=1, annot=False, center=0)\n",
        "heatmap(df=df.set_index([\"f_id\", \"i_id\"]).corr(method=\"pearson\"), figsize=(25, 20), font_scale=1, path=f\"{DATA_PATH}/X_ELA_correlation_pearson\", vmin=-1, vmax=1, annot=False, center=0)"
      ],
      "metadata": {
        "id": "xzn1_o2pAR1m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}