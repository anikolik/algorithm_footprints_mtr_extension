{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# %cd #YOUR PATH TO THE NOTEBOOK FOLDER IN GOOGLE COLAB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2BH_-3DlMrp",
        "outputId": "7806072d-b5d4-4a42-8d49-7135c4ee202d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkCbiu3XF9Fz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from configuration import experiment_id as EXPERIMENT_ID\n",
        "from configuration import data_root as DATA_ROOT\n",
        "from configuration import data_path as DATA_PATH\n",
        "from configuration import budget as BUDGET\n",
        "from configuration import algorithms as ALGORITHMS\n",
        "from configuration import n_iid as N_IID\n",
        "\n",
        "DATA_PATH"
      ],
      "metadata": {
        "id": "yh-QG7L3rm0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "BUDGET"
      ],
      "metadata": {
        "id": "AUpbGug7AVyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALGORITHMS"
      ],
      "metadata": {
        "id": "Z34qEE4E06oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_IID"
      ],
      "metadata": {
        "id": "rihUZvwd07Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(X_path, y_path):\n",
        "    \"\"\"Load feature and target data from specified paths.\"\"\"\n",
        "    X = pd.read_csv(X_path)\n",
        "    y = pd.read_csv(y_path)\n",
        "    return X, y\n",
        "\n",
        "def merge_data(X, y):\n",
        "    \"\"\"Merge features and targets into a single DataFrame and set index.\"\"\"\n",
        "    data = pd.merge(X, y, on=[\"f_id\", \"i_id\"])\n",
        "    return data.set_index([\"f_id\", \"i_id\"])\n",
        "\n",
        "def split_data(data, algorithms):\n",
        "    \"\"\"Split data into features and targets, and perform train/test split.\"\"\"\n",
        "    y = data[algorithms]\n",
        "    X = data.drop(columns=algorithms)\n",
        "    # Generate random train/test indices\n",
        "    np.random.seed(1)\n",
        "    i_ids = np.random.choice(range(45), size=5, replace=False).tolist()\n",
        "    print(f\"i_ids in the test dataset: {i_ids}\")\n",
        "    X_train = X[~X.index.get_level_values(\"i_id\").isin(i_ids)]\n",
        "    y_train = y[~y.index.get_level_values(\"i_id\").isin(i_ids)]\n",
        "    X_test = X[X.index.get_level_values(\"i_id\").isin(i_ids)]\n",
        "    y_test = y[y.index.get_level_values(\"i_id\").isin(i_ids)]\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def scale_features(X_train, X_test):\n",
        "    \"\"\"Scale features using MinMaxScaler and return scaled data.\"\"\"\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "    return X_train_scaled, X_test_scaled\n",
        "\n",
        "def save_data(X_train, y_train, X_test, y_test, save_path):\n",
        "    \"\"\"Save train and test datasets to the specified path.\"\"\"\n",
        "    X_train.reset_index().to_csv(f\"{save_path}/X_train.csv\", index=False)\n",
        "    y_train.reset_index().to_csv(f\"{save_path}/y_train.csv\", index=False)\n",
        "    X_test.reset_index().to_csv(f\"{save_path}/X_test.csv\", index=False)\n",
        "    y_test.reset_index().to_csv(f\"{save_path}/y_test.csv\", index=False)\n",
        "\n",
        "def create_datasets_mtr(X_path, y_path, algorithms, save_path):\n",
        "    \"\"\"High-level function to process and save dataset.\"\"\"\n",
        "    X, y = load_data(X_path, y_path)\n",
        "    data = merge_data(X, y)\n",
        "    print(\"Preview dataset: \")\n",
        "    print(data.head())\n",
        "    print(data.shape)\n",
        "    X_train, y_train, X_test, y_test = split_data(data, algorithms)\n",
        "    X_train_scaled, X_test_scaled = scale_features(X_train, X_test)\n",
        "    save_data(X_train_scaled, y_train, X_test_scaled, y_test, save_path)\n",
        "\n",
        "# Define data paths\n",
        "X_PATH = f\"{DATA_PATH}/X.csv\"\n",
        "Y_PATH = f\"{DATA_PATH}/y.csv\"\n",
        "\n",
        "create_datasets_mtr(X_PATH, Y_PATH, ALGORITHMS, DATA_PATH)"
      ],
      "metadata": {
        "id": "at4o3Bur0kCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot target data"
      ],
      "metadata": {
        "id": "nDBTxBUD4jM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_data(file_path, id_vars):\n",
        "    \"\"\"Load CSV file and prepare for plotting.\"\"\"\n",
        "    data = pd.read_csv(file_path, dtype={\"f_id\": str, \"i_id\": str})\n",
        "    return data.melt(id_vars=id_vars).rename(columns={\"variable\": \"algorithm\", \"value\": \"ground_truth\"})\n",
        "\n",
        "def plot_data(data, save_path, plot_title):\n",
        "    \"\"\"Plot scatterplot of the ground truth data.\"\"\"\n",
        "    sns.set_theme(style='white', font_scale=1.1)\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    sns.scatterplot(\n",
        "        data=data,\n",
        "        x=\"f_id\",\n",
        "        y=\"ground_truth\",\n",
        "        hue=\"algorithm\",\n",
        "        style=\"algorithm\",\n",
        "        alpha=0.5,\n",
        "        s=100,\n",
        "        ax=ax\n",
        "    )\n",
        "    plt.gca().xaxis.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.ylim(-0.3, 8)\n",
        "    plt.title(plot_title)\n",
        "    plt.savefig(f\"{save_path}/ground_truth_{plot_title.lower().replace(' ', '_')}.png\")\n",
        "    plt.savefig(f\"{save_path}/ground_truth_{plot_title.lower().replace(' ', '_')}.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "train_data_path = f\"{DATA_PATH}/y_train.csv\"\n",
        "test_data_path = f\"{DATA_PATH}/y_test.csv\"\n",
        "\n",
        "# Load and prepare data for plotting\n",
        "train_data = load_and_prepare_data(train_data_path, id_vars=[\"f_id\", \"i_id\"])\n",
        "test_data = load_and_prepare_data(test_data_path, id_vars=[\"f_id\", \"i_id\"])\n",
        "\n",
        "# Plot data\n",
        "plot_data(train_data, DATA_PATH, \"Train Data Ground Truth\")\n",
        "plot_data(test_data, DATA_PATH, \"Test Data Ground Truth\")"
      ],
      "metadata": {
        "id": "-6-vuWxxM7v-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}